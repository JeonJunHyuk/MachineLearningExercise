{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X:  (150, 4)\n",
      "Size of y:  (150,)\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "print('Size of X: ', X.shape)\n",
    "print('Size of y: ', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Holdout method\n",
    "- 데이터를 training set과 test set으로 구분\n",
    "- `sklearn.model_selection.train_test_split` 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X_train:  (105, 4)\n",
      "Size of X_test:  (45, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234, stratify=y)\n",
    "print('Size of X_train: ', X_train.shape)\n",
    "print('Size of X_test: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      0.73      0.85        15\n",
      "           2       0.79      1.00      0.88        15\n",
      "\n",
      "    accuracy                           0.91        45\n",
      "   macro avg       0.93      0.91      0.91        45\n",
      "weighted avg       0.93      0.91      0.91        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_test_hat = model.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 3-way holdout method\n",
    "- 데이터를 training set, validation set (또는 development set), test set으로 구분\n",
    "- 아래 함수를 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(X, y, val_size=0.3, test_size=0.2, random_state=123, stratify_bool=True):\n",
    "    if stratify_bool:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                            test_size=test_size, \n",
    "                                                            random_state=random_state,\n",
    "                                                            stratify=y)\n",
    "        val_size_rev = val_size / (1 - test_size)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
    "                                                          test_size=val_size_rev,\n",
    "                                                          random_state=random_state,\n",
    "                                                          stratify=y_train)\n",
    "        return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                            test_size=test_size, \n",
    "                                                            random_state=random_state)\n",
    "        val_size_rev = val_size / (1 - test_size)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
    "                                                          test_size=val_size_rev,\n",
    "                                                          random_state=random_state)\n",
    "        return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X_train:  (75, 4)\n",
      "Size of X_val:  (45, 4)\n",
      "Size of X_test:  (30, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(X, y, val_size=0.3, test_size=0.2, random_state=1234, stratify_bool=True)\n",
    "print('Size of X_train: ', X_train.shape)\n",
    "print('Size of X_val: ', X_val.shape)\n",
    "print('Size of X_test: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Logistic Regression (C = 0.100000) ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      0.40      0.57        15\n",
      "           2       0.62      1.00      0.77        15\n",
      "\n",
      "    accuracy                           0.80        45\n",
      "   macro avg       0.88      0.80      0.78        45\n",
      "weighted avg       0.88      0.80      0.78        45\n",
      "\n",
      "\n",
      "== Logistic Regression (C = 1.000000) ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      0.93      0.97        15\n",
      "           2       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "\n",
      "== Logistic Regression (C = 10.000000) ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00        15\n",
      "           2       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C_set = [0.1, 1, 10]\n",
    "models = []\n",
    "for C in C_set:\n",
    "    print('== Logistic Regression (C = %f) ==' % C)\n",
    "    model = LogisticRegression(C=C)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_val_hat = model.predict(X_val)\n",
    "    print(metrics.classification_report(y_val, y_val_hat))\n",
    "    print()\n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 최적의 하이퍼파라미터로 training set에 학습된 모델을 그대로 test set에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.90      0.95        10\n",
      "           2       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = models[2]\n",
    "y_test_hat = best_model.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 최적의 하이퍼파라미터로 training set + validation set에 다시 재학습한 후, 이를 test set에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4)\n",
      "(120,)\n"
     ]
    }
   ],
   "source": [
    "X_concat = np.concatenate((X_train, X_val), axis=0)\n",
    "y_concat = np.concatenate((y_train, y_val), axis=0)\n",
    "print(X_concat.shape)\n",
    "print(y_concat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 재학습\n",
    "best_model = models[2]\n",
    "best_model.fit(X_concat, y_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "           2       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.94      0.93      0.93        30\n",
      "weighted avg       0.94      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_hat = best_model.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cross-validation\n",
    "- 데이터를 먼저 training set, test set으로 구분\n",
    "- Training set을 cross-validation하여 최적의 모델 (하이퍼)파라미터를 찾고 이를 test set에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='https://scikit-learn.org/stable/_images/grid_search_cross_validation.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X_train:  (105, 4)\n",
      "Size of X_test:  (45, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234, stratify=y)\n",
    "print('Size of X_train: ', X_train.shape)\n",
    "print('Size of X_test: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Logistic Regression (C = 0.100000) ==\n",
      "Accuracy: 0.8095 (+/- 0.1562)\n",
      "== Logistic Regression (C = 1.000000) ==\n",
      "Accuracy: 0.9429 (+/- 0.0373)\n",
      "== Logistic Regression (C = 10.000000) ==\n",
      "Accuracy: 0.9619 (+/- 0.0698)\n"
     ]
    }
   ],
   "source": [
    "C_set = [0.1, 1, 10]\n",
    "\n",
    "for C in C_set:\n",
    "    print('== Logistic Regression (C = %f) ==' % C)\n",
    "    model = LogisticRegression(C=C)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    \n",
    "    print('Accuracy: %.4f (+/- %.4f)' % (scores.mean(), scores.std()*1.96))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 최적의 하이퍼파라미터로 training set에 학습된 모델을 그대로 test set에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      0.80      0.89        15\n",
      "           2       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.94      0.93      0.93        45\n",
      "weighted avg       0.94      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_C = C_set[2]\n",
    "best_model = LogisticRegression(C=best_C)\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "y_test_hat = best_model.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 최적의 하이퍼파라미터로 training set + validation set에 다시 재학습한 후, 이를 test set에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "X_concat = np.concatenate((X_train, X_val), axis=0)\n",
    "y_concat = np.concatenate((y_train, y_val), axis=0)\n",
    "print(X_concat.shape)\n",
    "print(y_concat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 재학습\n",
    "best_C = C_set[2]\n",
    "best_model = LogisticRegression(C=best_C)\n",
    "\n",
    "best_model.fit(X_concat, y_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       0.92      0.80      0.86        15\n",
      "           2       0.82      0.93      0.87        15\n",
      "\n",
      "    accuracy                           0.91        45\n",
      "   macro avg       0.92      0.91      0.91        45\n",
      "weighted avg       0.92      0.91      0.91        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_hat = best_model.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cross-validation with hyperparameter search\n",
    "- `sklearn.model_selection.GridSearchCV` 또는 `sklearn.model_selection.RandomizedSearchCV` 적용\n",
    "- 다음 시간에..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
