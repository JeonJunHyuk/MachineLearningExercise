{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Making the artificial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = 2\n",
    "x_train, y_train = make_blobs(n_samples=100, n_features=n_dim, centers=[[1,1],[-1,-1]], shuffle=True)\n",
    "x_test, y_test = make_blobs(n_samples=30, n_features=n_dim, centers=[[1,1],[-1,-1]], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train[:10,:])\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "plt.figure()\n",
    "plt.scatter(x_train[(y_train==0),0], x_train[(y_train==0),1], c='blue', marker='o')\n",
    "plt.scatter(x_train[(y_train==1),0], x_train[(y_train==1),1], c='red', marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "plt.figure()\n",
    "plt.scatter(x_test[(y_test==0),0], x_test[(y_test==0),1], c='blue', marker='+')\n",
    "plt.scatter(x_test[(y_test==1),0], x_test[(y_test==1),1], c='red', marker='+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data + Test data\n",
    "plt.figure()\n",
    "plt.scatter(x_train[(y_train==0),0], x_train[(y_train==0),1], c='blue', marker='o')\n",
    "plt.scatter(x_train[(y_train==1),0], x_train[(y_train==1),1], c='red', marker='o')\n",
    "plt.scatter(x_test[(y_test==0),0], x_test[(y_test==0),1], c='blue', marker='+')\n",
    "plt.scatter(x_test[(y_test==1),0], x_test[(y_test==1),1], c='red', marker='+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic function (a.k.a., softmax function, sigmoid function)\n",
    "def logistic(x):\n",
    "    return 1.0 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(x, beta):\n",
    "    logit = np.dot(x, beta)\n",
    "    return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = [0.1, -0.1]\n",
    "y_hat = logistic(logit(x=x_train, beta=beta)) # Y = 1일 확률\n",
    "print(y_hat[:10])\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_log_likelihood(x, y, beta, avg=False):\n",
    "    y_hat = logistic(logit(x=x_train, beta=beta))\n",
    "    log_likelihood = y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat)\n",
    "    if not avg:\n",
    "        return -log_likelihood\n",
    "    else:\n",
    "        return np.mean(-log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss = negative_log_likelihood(x=x_train, y=y_train, beta=beta)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Learning logistic regression model\n",
    "- Using batch gradient descent method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(x, y, num_steps=50, learning_rate=0.01):\n",
    "    initial_beta = np.asarray([10, 10])\n",
    "    beta_list = []\n",
    "    beta_list.append(initial_beta)\n",
    "    beta = initial_beta\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        y_hat = logistic(logit(x=x_train, beta=beta))\n",
    "        gradient = np.dot(x.T, y_hat - y)\n",
    "        new_beta = beta - learning_rate * gradient\n",
    "        loss = negative_log_likelihood(x, y, beta, avg=True)\n",
    "        \n",
    "        # Print\n",
    "        loss_tracking = '[%d step] loss %.4f' % (step, loss)\n",
    "        beta_equation = '[%.2f %.2f] = [%.2f %.2f] - %.2f * [%.2f %.2f]' % (new_beta[0], new_beta[1], beta[0], beta[1], learning_rate, gradient[0], gradient[1])\n",
    "        print(loss_tracking, '\\t', beta_equation)\n",
    "        \n",
    "        beta_list.append(new_beta)\n",
    "        beta = new_beta\n",
    "        \n",
    "    return beta, beta_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "beta, beta_list = logistic_regression(x=x_train, y=y_train, num_steps=100, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(beta)\n",
    "print(beta_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comes from Kyunghyun Cho's ML lecture (https://github.com/nyu-dl/Intro_to_ML_Lecture_Note)\n",
    "def vis_hyperplane(beta, style='k--'):\n",
    "\n",
    "    lim0 = plt.gca().get_xlim()\n",
    "    lim1 = plt.gca().get_ylim()\n",
    "    m0, m1 = lim0[0], lim0[1]\n",
    "\n",
    "    intercept0 = -(beta[0] * m0 + beta[-1])/beta[1]\n",
    "    intercept1 = -(beta[0] * m1 + beta[-1])/beta[1]\n",
    "    \n",
    "    plt1, = plt.plot([m0, m1], [intercept0, intercept1], style)\n",
    "\n",
    "    plt.gca().set_xlim(lim0)\n",
    "    plt.gca().set_ylim(lim1)\n",
    "        \n",
    "    return plt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data + Hyperplane\n",
    "plt.figure()\n",
    "plt.scatter(x_train[(y_train==0),0], x_train[(y_train==0),1], c='blue', marker='o')\n",
    "plt.scatter(x_train[(y_train==1),0], x_train[(y_train==1),1], c='red', marker='o')\n",
    "\n",
    "initial_beta_plot = vis_hyperplane(beta_list[0], 'k--')\n",
    "beta_plot_10 = vis_hyperplane(beta_list[9], 'b--')\n",
    "beta_plot_15 = vis_hyperplane(beta_list[14], 'r--')\n",
    "beta_plot = vis_hyperplane(beta, 'g--')\n",
    "\n",
    "plt.legend([initial_beta_plot, beta_plot_10, beta_plot_15, beta_plot], ['Randomly initialized beta', 'Learned beta(10th updated)', 'Learned beta(15th updated)', 'Learned beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data + Hyperplane\n",
    "plt.figure()\n",
    "plt.scatter(x_test[(y_test==0),0], x_test[(y_test==0),1], c='blue', marker='+')\n",
    "plt.scatter(x_test[(y_test==1),0], x_test[(y_test==1),1], c='red', marker='+')\n",
    "\n",
    "initial_beta_plot = vis_hyperplane(beta_list[0], 'k--')\n",
    "beta_plot = vis_hyperplane(beta, 'g--')\n",
    "\n",
    "plt.legend([initial_beta_plot, beta_plot], ['Randomly initialized beta', 'Learned beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data + Test data\n",
    "plt.figure()\n",
    "plt.scatter(x_train[(y_train==0),0], x_train[(y_train==0),1], c='blue', marker='o', alpha=0.1)\n",
    "plt.scatter(x_train[(y_train==1),0], x_train[(y_train==1),1], c='red', marker='o', alpha=0.1)\n",
    "plt.scatter(x_test[(y_test==0),0], x_test[(y_test==0),1], c='blue', marker='+')\n",
    "plt.scatter(x_test[(y_test==1),0], x_test[(y_test==1),1], c='red', marker='+')\n",
    "\n",
    "initial_beta_plot = vis_hyperplane(beta_list[0], 'k--')\n",
    "beta_plot = vis_hyperplane(beta, 'g--')\n",
    "\n",
    "plt.legend([initial_beta_plot, beta_plot], ['Randomly initialized beta', 'Learned beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
