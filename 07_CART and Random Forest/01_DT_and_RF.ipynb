{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle [Gender Recognition by Voice]\n",
    "- https://www.kaggle.com/primaryobjects/voicegender\n",
    "\n",
    "### Kernel을 참조하여 데이터 전처리 및 시각화를 진행함\n",
    "- https://www.kaggle.com/sushanthiray/d/primaryobjects/voicegender/experimenting-with-neural-networks-in-tensorflow/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/voice.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DataFrame에 null이 있으면 True, 없으면 False를 원 데이터 형태로 표현\n",
    "pd.isnull(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 만약 True가 있으면 DataFrame의 해당 인덱스가 출력됨\n",
    "np.where(pd.isnull(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where([True, False, True, False, False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import missingno\n",
    "missingno.matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome. We don't have any null's in the dataset. One less thing to worry about. Now let us check how the labels are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of male: {}\".format(df[df.label == 'male'].shape[0]))\n",
    "print(\"Number of female: {}\".format(df[df.label == 'female'].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = plt.cm.viridis\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "sns.heatmap(df.iloc[:,:-1].astype(float).corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While looking at the plot, we can figure out some interesting correlations. If you look at meanfreq vs centroid their correlation is maximum possible value of 1. Same is the case with maxdom and dfrange. So essentially we could filter out these features and still get an equivalent performance as they aren't adding any new information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Validation (dev) / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
    "                                                  test_size = 0.375,\n",
    "                                                  random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training 50%, validation 30%, test 20%\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree modeling\n",
    "- 나무 깊이에 대해 다른 파라미터값 부여\n",
    "- 각각의 파라미터에 대해 Train set으로 모델을 생성한 후, Validation set으로 성능 평가 ==> 가장 성능이 좋은 파라미터와 모델 선택\n",
    "- Test set으로 모델의 예측 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "depth_set = [3, 4, 5, 6, 7, 8, 9, 10]\n",
    "dt_models = []\n",
    "accuracy_set = []\n",
    "cm_set = []\n",
    "train_accuracy_set = []\n",
    "\n",
    "for depth in depth_set:\n",
    "    model = DecisionTreeClassifier(max_depth = depth, random_state = 1)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_hat = model.predict(X_train)\n",
    "    y_val_hat = model.predict(X_val)\n",
    "    train_accuracy = metrics.accuracy_score(y_train, \n",
    "                                            y_train_hat)\n",
    "    accuracy = metrics.accuracy_score(y_val, y_val_hat)\n",
    "    cm = metrics.confusion_matrix(y_val, y_val_hat)\n",
    "    \n",
    "    dt_models.append(model)\n",
    "    accuracy_set.append(accuracy)\n",
    "    train_accuracy_set.append(train_accuracy)\n",
    "    cm_set.append(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(accuracy_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(train_accuracy_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 탐색 결과, 가장 좋은 모델과 Validation set에 대한 정확도\n",
    "max_value = max(accuracy_set)\n",
    "max_index = accuracy_set.index(max_value)\n",
    "print(max_index)\n",
    "print(max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 좋은 모델\n",
    "dt_models[max_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 좋은 모델을 가져와 Test set에 대해 예측 성능 평가\n",
    "y_test_hat = dt_models[max_index].predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_test_hat))\n",
    "print(metrics.confusion_matrix(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "- 나무의 갯수, 각 나무의 변수 선택 수를 파라미터로 설정\n",
    "- 각각의 파라미터 집합에 대해 Train set으로 모델을 생성한 후, Validation set으로 성능 평가 ==> 가장 성능이 좋은 파라미터와 모델 선택\n",
    "- Test set으로 모델의 예측 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_set = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "max_features_set = ['auto', 'log2']\n",
    "\n",
    "rf_models = []\n",
    "accuracy_set = []\n",
    "cm_set = []\n",
    "\n",
    "for n_estimators in n_estimators_set:\n",
    "    for max_features in max_features_set:\n",
    "        rf = RandomForestClassifier(n_estimators = n_estimators,\n",
    "                                    max_features = max_features,\n",
    "                                    random_state = 123)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_val_hat = rf.predict(X_val)\n",
    "        accuracy = metrics.accuracy_score(y_val, y_val_hat)\n",
    "        cm = metrics.confusion_matrix(y_val, y_val_hat)\n",
    "\n",
    "        rf_models.append(rf)\n",
    "        accuracy_set.append(accuracy)\n",
    "        cm_set.append(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 탐색 결과, 가장 좋은 모델과 Validation set에 대한 정확도\n",
    "max_value = max(accuracy_set)\n",
    "max_index = accuracy_set.index(max_value)\n",
    "print(max_index)\n",
    "print(max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 좋은 모델\n",
    "rf_models[max_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 좋은 모델을 가져와 Test set에 대해 예측 성능 평가\n",
    "y_test_hat = rf_models[max_index].predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_test_hat))\n",
    "print(metrics.confusion_matrix(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = rf_models[max_index].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in zip(col_names, fi): print(i, '\\t', j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실습\n",
    "1. LogisticRegression, kNearestClassifier 등을 사용하여 모델 하이퍼파라미터 탐색 및 베스트 모델을 뽑아보세요.\n",
    "2. Decision Tree, Random Forest에 대해서 다른 후보군으로 모델 하이퍼파라미터 탐색을 및 베스트 모델을 뽑아보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Hyper-parameter caldidates\n",
    "penalty_set = ['l1', 'l2']\n",
    "C_set = [0.01, 0.1, 1, 10, 100]\n",
    "class_weight_set = [None, 'balanced']\n",
    "\n",
    "# 결과 저장을 미리 할당하기 위한 리스트 선언\n",
    "train_acc_set = []\n",
    "val_acc_set = []\n",
    "lrs = []\n",
    "\n",
    "for penalty in penalty_set:\n",
    "    for C in C_set:\n",
    "        for class_weight in class_weight_set:\n",
    "            lr = LogisticRegression(penalty=penalty, C=C, \n",
    "                                    class_weight=class_weight,\n",
    "                                    random_state=2072)\n",
    "            # Train the model\n",
    "            lr.fit(X_train, y_train)\n",
    "            lrs.append(lr)\n",
    "            \n",
    "            # Calculate training accuracy and validation accuracy\n",
    "            y_train_hat = lr.predict(X_train)\n",
    "            y_val_hat = lr.predict(X_val)\n",
    "            train_acc = metrics.accuracy_score(y_train, y_train_hat)\n",
    "            val_acc = metrics.accuracy_score(y_val, y_val_hat)\n",
    "            train_acc_set.append(train_acc)\n",
    "            val_acc_set.append(val_acc)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 탐색 결과, 가장 좋은 모델과 Validation set에 대한 정확도\n",
    "max_value = max(val_acc_set)\n",
    "max_index = val_acc_set.index(max_value)\n",
    "print(max_index)\n",
    "print(max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 가장 좋은 모델을 가져와 Test set에 대해 예측 성능 평가\n",
    "y_test_hat = lrs[max_index].predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_test_hat))\n",
    "print(metrics.confusion_matrix(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainining set과 Validation set을 합친 후 Test set에 대해 예측 성능 평가\n",
    "X_concat = pd.concat([X_train, X_val])\n",
    "y_concat = pd.concat([y_train, y_val])\n",
    "# 합친 데이터에 모델을 refit\n",
    "best_lr = lrs[max_index]\n",
    "best_lr.fit(X_concat, y_concat)\n",
    "# Test set에 대해 예측 성능 평가\n",
    "y_test_hat = best_lr.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_test_hat))\n",
    "print(metrics.confusion_matrix(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
